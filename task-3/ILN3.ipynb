{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "ILN3.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9XtIxjKbLb"
      },
      "source": [
        "# ILN3: WSD. El Algoritmo de Lesk simplificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5xmcTPJKbLg"
      },
      "source": [
        "Se trata de definir y usar una función que, dada una frase y utilizando el algoritmo de Lesk, desambigüe cada una de sus palabras con contenido. La signatura se construirá considerando la definición y los ejemplos de cada synset. Consultar el material de la sesión 4 donde se explica el algoritmo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejPNkuNpKbLh"
      },
      "source": [
        "1.- Definir la función ***wsd*** que dada una frase y usando el algoritmo de Lesk muestre por pantalla el resultado de la desambiguación de cada una de sus palabras. \n",
        "Para ello, para cada palabra de la frase *w* y para cada sentido *syn* de *w*, sin considerar las stopwords, se debe computar el\n",
        "solapamiento, es decir, el número de palabras en común entre la definición y ejemplos del sentido *syn* y la frase. El syn que maximice este solapamiento será el asignado a la palabra *w*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHeoB8JbOaoJ"
      },
      "source": [
        "EJEMPLO de salida del programa:\n",
        "\n",
        "wsd(\"We can be heroes just for one day\") \n",
        "\n",
        "... Analizando heroes (7 sentidos) --> hero.n.01 con solape 1\n",
        "\n",
        "a man distinguished by exceptional courage and nobility and strength\n",
        "\n",
        "... Analizando one (9 sentidos) --> one.s.05 con solape 2\n",
        "\n",
        "indefinite in time or position\n",
        "\n",
        "... Analizando day (10 sentidos) --> sidereal_day.n.01 con solape 2\n",
        "\n",
        "the time for one complete rotation of the earth relative to a particular star ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFGuDOZFKbLh"
      },
      "source": [
        "2.- Utilizar la función definida, wsd, sobre las frases:\n",
        "\n",
        "\"We can be heroes just for one day\"\n",
        "\n",
        "\"I saw a man who is 98 years old and can still walk and tell jokes\"\n",
        "\n",
        "\"We went to the bank to get money\"\n",
        "\n",
        "\"We are sitting on the bank of the river\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqvYDrW-4_Qi"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR9Pn1-lLb1u"
      },
      "source": [
        "def computeOverlap(ctx, glosa):\n",
        "  return glosa.count(ctx)\n",
        "\n",
        "def wsd(s):\n",
        "  context=nltk.word_tokenize(s)\n",
        "  print(\"\\n...Analizando la frase %s\" %(context))\n",
        "  stopwords = nltk.corpus.stopwords.words('english') \n",
        "  contentwords = [w for w in context if w.lower() not in stopwords]\n",
        "  for ctx in contentwords:\n",
        "    sensesDict = {}\n",
        "    example = ''\n",
        "    for sense in wn.synsets(ctx):\n",
        "      glosa = sense.definition() + ' ' + ' '.join(sense.examples())\n",
        "      sensesDict[sense] = computeOverlap(ctx, glosa)\n",
        "    res = list({k: v for k, v in sorted(sensesDict.items(), key=lambda item: item[1], reverse=True)}.items())[0]\n",
        "    print(\"\\n...Analizando \"+ctx+\" (\"+ str(len(list(wn.synsets(ctx)))) +\"sentidos) -> \" + str(res[0]) +\" con solape \" + str(res[1]))"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2EMfok5An6",
        "outputId": "e4bdf918-8d21-49b7-ebb8-9f6b513d8def"
      },
      "source": [
        "wsd('We can be heroes just for one day')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "...Analizando la frase ['We', 'can', 'be', 'heroes', 'just', 'for', 'one', 'day']\n",
            "\n",
            "...Analizando heroes (7sentidos) -> Synset('hero.n.01') con solape 1\n",
            "\n",
            "...Analizando one (9sentidos) -> Synset('one.n.01') con solape 2\n",
            "\n",
            "...Analizando day (10sentidos) -> Synset('day.n.02') con solape 4\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}