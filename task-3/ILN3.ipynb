{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "ILN3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MO9XtIxjKbLb"
      },
      "source": [
        "# ILN3: WSD. El Algoritmo de Lesk simplificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5xmcTPJKbLg"
      },
      "source": [
        "Se trata de definir y usar una función que, dada una frase y utilizando el algoritmo de Lesk, desambigüe cada una de sus palabras con contenido. La signatura se construirá considerando la definición y los ejemplos de cada synset. Consultar el material de la sesión 4 donde se explica el algoritmo. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ejPNkuNpKbLh"
      },
      "source": [
        "1.- Definir la función ***wsd*** que dada una frase y usando el algoritmo de Lesk muestre por pantalla el resultado de la desambiguación de cada una de sus palabras. \n",
        "Para ello, para cada palabra de la frase *w* y para cada sentido *syn* de *w*, sin considerar las stopwords, se debe computar el\n",
        "solapamiento, es decir, el número de palabras en común entre la definición y ejemplos del sentido *syn* y la frase. El syn que maximice este solapamiento será el asignado a la palabra *w*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EHeoB8JbOaoJ"
      },
      "source": [
        "EJEMPLO de salida del programa:\n",
        "\n",
        "wsd(\"We can be heroes just for one day\") \n",
        "\n",
        "... Analizando heroes (7 sentidos) --> hero.n.01 con solape 1\n",
        "\n",
        "a man distinguished by exceptional courage and nobility and strength\n",
        "\n",
        "... Analizando one (9 sentidos) --> one.s.05 con solape 2\n",
        "\n",
        "indefinite in time or position\n",
        "\n",
        "... Analizando day (10 sentidos) --> sidereal_day.n.01 con solape 2\n",
        "\n",
        "the time for one complete rotation of the earth relative to a particular star ..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFGuDOZFKbLh"
      },
      "source": [
        "2.- Utilizar la función definida, wsd, sobre las frases:\n",
        "\n",
        "\"We can be heroes just for one day\"\n",
        "\n",
        "\"I saw a man who is 98 years old and can still walk and tell jokes\"\n",
        "\n",
        "\"We went to the bank to get money\"\n",
        "\n",
        "\"We are sitting on the bank of the river\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqvYDrW-4_Qi",
        "outputId": "760fd138-4ddd-4f1c-e449-69d0b0b60ad2"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.corpus import wordnet as wn"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oR9Pn1-lLb1u"
      },
      "source": [
        "def computeOverlap(ctx, glosa):\n",
        "  return len(set(ctx) & set(glosa))\n",
        "\n",
        "def wsd(s):\n",
        "  context=nltk.word_tokenize(s)\n",
        "  print(\"\\n...Analizando la frase %s\" %(context))\n",
        "  stopwords = nltk.corpus.stopwords.words('english') \n",
        "  contentwords = [w for w in context if w.lower() not in stopwords]\n",
        "  for ctx in contentwords:\n",
        "    sensesDict = {}\n",
        "    for sense in wn.synsets(ctx):\n",
        "      glosa = []\n",
        "      for ex in sense.examples():\n",
        "        glosa += nltk.word_tokenize(ex)\n",
        "      glosa += nltk.word_tokenize(sense.definition())\n",
        "      sensesDict[sense] = computeOverlap(context, glosa)\n",
        "    res = list({k: v for k, v in sorted(sensesDict.items(), key=lambda item: item[1], reverse=True)}.items())[0]\n",
        "    print(\"\\n...Analizando \"+ ctx +\" (\"+ str(len(list(wn.synsets(ctx)))) + \"sentidos) -> \" + str(res[0]) + \" con solape \" + str(res[1]))"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL2EMfok5An6",
        "outputId": "e916b18e-7a33-43af-abcb-0b06a95474c1"
      },
      "source": [
        "wsd('We can be heroes just for one day')\n",
        "print('\\n')\n",
        "wsd('I saw a man who is 98 years old and can still walk and tell jokes')\n",
        "print('\\n')\n",
        "wsd('We went to the bank to get money')\n",
        "print('\\n')\n",
        "wsd('We are sitting on the bank of the river')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "...Analizando la frase ['We', 'can', 'be', 'heroes', 'just', 'for', 'one', 'day']\n",
            "\n",
            "...Analizando heroes (7sentidos) -> Synset('hero.n.01') con solape 1\n",
            "\n",
            "...Analizando one (9sentidos) -> Synset('one.s.05') con solape 2\n",
            "\n",
            "...Analizando day (10sentidos) -> Synset('sidereal_day.n.01') con solape 3\n",
            "\n",
            "\n",
            "\n",
            "...Analizando la frase ['I', 'saw', 'a', 'man', 'who', 'is', '98', 'years', 'old', 'and', 'can', 'still', 'walk', 'and', 'tell', 'jokes']\n",
            "\n",
            "...Analizando saw (28sentidos) -> Synset('see.v.01') con solape 3\n",
            "\n",
            "...Analizando man (13sentidos) -> Synset('man.n.01') con solape 4\n",
            "\n",
            "...Analizando 98 (1sentidos) -> Synset('ninety-eight.s.01') con solape 0\n",
            "\n",
            "...Analizando years (7sentidos) -> Synset('old_age.n.01') con solape 4\n",
            "\n",
            "...Analizando old (9sentidos) -> Synset('old.a.01') con solape 3\n",
            "\n",
            "...Analizando still (18sentidos) -> Synset('however.r.01') con solape 4\n",
            "\n",
            "...Analizando walk (17sentidos) -> Synset('walk.v.01') con solape 3\n",
            "\n",
            "...Analizando tell (9sentidos) -> Synset('assure.v.02') con solape 6\n",
            "\n",
            "...Analizando jokes (6sentidos) -> Synset('joke.v.01') con solape 3\n",
            "\n",
            "\n",
            "\n",
            "...Analizando la frase ['We', 'went', 'to', 'the', 'bank', 'to', 'get', 'money']\n",
            "\n",
            "...Analizando went (30sentidos) -> Synset('travel.v.01') con solape 4\n",
            "\n",
            "...Analizando bank (18sentidos) -> Synset('depository_financial_institution.n.01') con solape 3\n",
            "\n",
            "...Analizando get (37sentidos) -> Synset('get_down.v.07') con solape 4\n",
            "\n",
            "...Analizando money (3sentidos) -> Synset('money.n.01') con solape 3\n",
            "\n",
            "\n",
            "\n",
            "...Analizando la frase ['We', 'are', 'sitting', 'on', 'the', 'bank', 'of', 'the', 'river']\n",
            "\n",
            "...Analizando sitting (16sentidos) -> Synset('sitting.n.01') con solape 3\n",
            "\n",
            "...Analizando bank (18sentidos) -> Synset('bank.n.01') con solape 5\n",
            "\n",
            "...Analizando river (1sentidos) -> Synset('river.n.01') con solape 3\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}